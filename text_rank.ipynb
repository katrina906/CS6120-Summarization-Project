{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_rank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJuxeHXLNKBSFjhJxNVYeT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katrina906/CS6120-Summarization-Project/blob/main/text_rank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLDzqav1L3WA"
      },
      "source": [
        "# https://stackabuse.com/text-summarization-with-nltk-in-python/ -- TODO baseline method, just summing weights in sentences "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJeuS-7H7Yy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2d5f5b-0c9d-4b10-da3e-a4e8abc936f1"
      },
      "source": [
        "!pip install rouge-score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K99-qm9GrHPX"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import pickle\r\n",
        "import string\r\n",
        "import re\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import nltk\r\n",
        "import itertools\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.feature_extraction import DictVectorizer\r\n",
        "from collections import Counter, OrderedDict\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "import networkx as nx\r\n",
        "from rouge_score import rouge_scorer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kSai_eCrMBW"
      },
      "source": [
        "#from google.colab import drive\r\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1p-6myxP_V"
      },
      "source": [
        "# load data\r\n",
        "df = pd.read_pickle(\"/content/drive/MyDrive/data/cleaned_df.pkl\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW8tlcZihfAr"
      },
      "source": [
        "# clean sentences for similarity comparisons; not for final display\r\n",
        "# TODO: stemming or lemmatization? \r\n",
        "# TODO: stop word exclusion? \r\n",
        "def text_cleaning(doc):\r\n",
        "  # downcase everything\r\n",
        "  df['sentences_cleaned'] = df.sentences.apply(lambda text: [sentence.lower() for sentence in text])\r\n",
        "  # remove punctuation \r\n",
        "  df.sentences_cleaned = df.sentences_cleaned.apply(lambda text: [re.sub(\"[^\\w\\s]\", '', sentence) for sentence in text])\r\n",
        "\r\n",
        "  return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzEExkib6-l5"
      },
      "source": [
        "### Vector Representation \r\n",
        "Default: unigram bag of words with counts\r\n",
        "Options: \r\n",
        "  - binary: bag of words with binary indicators rather than counts (don't use with tfidf)\r\n",
        "  - tf: term frequency normalization \r\n",
        "    - Same as default if cosine similarity. Cosine similarity does the normalization (double check this!!)\r\n",
        "  - idf: inverse document normalization \r\n",
        "  - include_bigrams/include_trigrams: include bigrams and/or trigrams of words in addition to unigrams as distinct tokens in bag of words\r\n",
        "    - Gives sense of order in sentence, capture _concepts_ rather than just individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rATG9pYPMN7p"
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "#!unzip glove*.zip"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpYInOhegSZU"
      },
      "source": [
        "#wv = fasttext.load_model(\"/content/drive/MyDrive/data/wiki.en.bin\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9sUtBS3gMLy"
      },
      "source": [
        "#!pip install fasttext\r\n",
        "#import fasttext"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxDh393Ow2Ze"
      },
      "source": [
        "# vector representation of words in each sentence in document \r\n",
        "# TODO: try embeddings - fasttext\r\n",
        "def vector_representation(doc, configuration):\r\n",
        "\r\n",
        "  # list of words in each sentence \r\n",
        "  words = [sentence.split() for sentence in doc]\r\n",
        "\r\n",
        "  if 'bow' in configuration:\r\n",
        "\r\n",
        "    # include bigrams and/or trigrams (in addition to unigrams) in bow \r\n",
        "    grams = []\r\n",
        "    if 'bigram' in configuration or 'all' in configuration:\r\n",
        "      bigrams = [list(nltk.bigrams(sentence)) for sentence in words]\r\n",
        "      grams.append([[words[0] + ' ' + words[1] for words in sentence] for sentence in bigrams]) # combine tuples of words into string\r\n",
        "    if 'trigram' in configuration or 'all' in configuration:\r\n",
        "      trigrams = [list(nltk.trigrams(sentence)) for sentence in words]\r\n",
        "      grams.append([[words[0] + ' ' + words[1] + ' ' + words[2] for words in sentence] for sentence in trigrams]) # combine tuples of words into string\r\n",
        "    # concat with unigrams per sentence\r\n",
        "    for i in range(len(grams)):\r\n",
        "      words = [grams[i][j] + words[j] for j in range(len(words))] \r\n",
        "\r\n",
        "    # bag of words with binary indicators for words/n-grams rather than counts\r\n",
        "    if 'binary' in configuration: \r\n",
        "      words = [set(sentence) for sentence in words]\r\n",
        "\r\n",
        "    # bag of words: # sentences x # unique words\r\n",
        "    vec = DictVectorizer()\r\n",
        "    bow = vec.fit_transform(Counter(f) for f in words)\r\n",
        "\r\n",
        "    # term frequency normalization\r\n",
        "    if 'tf' in configuration: \r\n",
        "      tfidf_transformer = TfidfTransformer(use_idf = False)\r\n",
        "      tfidf = tfidf_transformer.fit_transform(bow)\r\n",
        "      return tfidf\r\n",
        "    # term frequency-inverse document frequency normalization\r\n",
        "    if 'tfidf' in configuration:\r\n",
        "      tfidf_transformer = TfidfTransformer(use_idf = True)\r\n",
        "      tfidf = tfidf_transformer.fit_transform(bow)\r\n",
        "      return tfidf\r\n",
        "\r\n",
        "    return bow\r\n",
        "\r\n",
        "  if 'embedding' in configuration:\r\n",
        "\r\n",
        "    if 'glove' in configuration:\r\n",
        "      # Extract glove word vectors as dictionary - code from https://www.analyticsvidhya.com/blog/2018/11/introduction-text-summarization-textrank-python/\r\n",
        "      # 100 length vector for each word \r\n",
        "      word_embeddings = {}\r\n",
        "      f = open('glove.6B.100d.txt', encoding='utf-8')\r\n",
        "      for line in f:\r\n",
        "          values = line.split()\r\n",
        "          word = values[0]\r\n",
        "          coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "          word_embeddings[word] = coefs\r\n",
        "      f.close()\r\n",
        "\r\n",
        "      # find average of word embeddings for each sentence \r\n",
        "      # if unknown word, give embedding = 0 \r\n",
        "      sentence_vectors = []\r\n",
        "      for sentence in doc_processed:\r\n",
        "        sentence_vectors.append(sum([word_embeddings.get(word, np.zeros(100,)) for word in sentence.split()])/(len(sentence.split())))\r\n",
        "\r\n",
        "      return np.array(sentence_vectors)\r\n",
        "\r\n",
        "    # fasttext. Advantage: generate embeddings for out of vocabulary words based on their parts\r\n",
        "    # possible extension: continued training on specific corpus. Probably unnecessary since wikipedia and news article words should be similar"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fl60wuOr-C2"
      },
      "source": [
        "# TODO: other similarity metrics?\r\n",
        "# TODO: other algorithms\r\n",
        "def pagerank(bow):\r\n",
        "  # similarity matrix between sentences\r\n",
        "  sim =  cosine_similarity(bow)\r\n",
        "  # graph where node = sentence, edge weight = simialarity score\r\n",
        "  G = nx.from_numpy_array(sim)\r\n",
        "  # page rank\r\n",
        "  pr = nx.pagerank(G)\r\n",
        "\r\n",
        "  return pr"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6uxY2t9y4x3"
      },
      "source": [
        "def extract_summary(pr, doc, config):\r\n",
        "  # sort keys in order of page rank\r\n",
        "  bestkeys = sorted(pr, key=pr.get, reverse=True)\r\n",
        "  # summary based on number of sentences \r\n",
        "  if 'num_sentences' in config:\r\n",
        "    max_sentences = int(np.floor(len(doc) / 6)) # average 6 summary sentences per doc sentence\r\n",
        "    return [doc[i] for i in  bestkeys[0:max_sentences]]\r\n",
        "  # summary based on number of words\r\n",
        "  # text sentences much longer than summary sentences\r\n",
        "  if 'num_words_gt' in config or 'num_words_lt' in config:\r\n",
        "    summary = []\r\n",
        "    num_words = 0\r\n",
        "    max_words = np.floor(len(''.join(doc).split(' ')) / 20) # average 20 summary words per text word\r\n",
        "    for i in bestkeys:\r\n",
        "      num_words += len(doc[i].split(' ')) \r\n",
        "      # strict version: words in summary must be less than threshold\r\n",
        "      if 'num_words_lt' in config:\r\n",
        "        if num_words >= max_words:\r\n",
        "          return summary\r\n",
        "        summary.append(doc[i])\r\n",
        "      # less strict version: can go over limit by 1 sentence \r\n",
        "      elif 'num_words_gt' in config:\r\n",
        "        summary.append(doc[i])\r\n",
        "        if num_words >= max_words:\r\n",
        "          return summary"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkVFZ2LEeEX4"
      },
      "source": [
        "### Evaluation \r\n",
        "ROUGE metric:\r\n",
        "https://kavita-ganesan.com/what-is-rouge-and-how-it-works-for-evaluation-of-summaries/#.YEKJyI5KiUl   \r\n",
        "- Precision = # overlapping ngrams / # total ngrams in produced summary \r\n",
        "  - Measure of junk. Did we produce a lot in the generated summary that is not in the actual summary?\r\n",
        "  - Important if we don't manually set the length. The generated summary could be very long which causes good recall\r\n",
        "- Recall = # overlapping ngrams / # total ngrams in label summary  \r\n",
        "  - Did we get all the words in the actual summary?\r\n",
        "- F1 = harmonic mean\r\n",
        "- N-Gram vs. LCS. Do we care about order? Don't need it to measure fluency/proper syntax. But ordering of words can indicate phrases \r\n",
        "\r\n",
        "Cons: \r\n",
        "- Doesn't look at sentence structure --> doesn't apply here because using correct sentences\r\n",
        "- Doesn't consider meaning -- same words could have different meaning   \r\n",
        "  \r\n",
        "Also considered BLEU, but only gives precision.     \r\n",
        "https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9IsZ0MU7e6B"
      },
      "source": [
        "def evaluate(predicted_summary, actual_summary):\r\n",
        "  # TODO: unigram, bigram etc. models for rouge? - do we care about the order of the words?\r\n",
        "  scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer = False)\r\n",
        "  rouge = scorer.score(''.join(predicted_summary), ''.join(actual_summary))\r\n",
        "\r\n",
        "  return rouge"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izB1kImY9oEK"
      },
      "source": [
        "# TODO create matrix of configurations to iterate through\r\n",
        "  # report config with best precision, best recall, best fmeasure \r\n",
        "  # loop over all documents and average results "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2TBmrUoHLcZ"
      },
      "source": [
        "# TODO evaluation strategy. average of rouge1, rouge2, rouge3 (like bleu with weights?). then fmeasure? preicision and recall equally important? \r\n",
        "  # do some algorithms/configurations do better in precision and others do better in recall? \r\n",
        "# TODO compare evaluations between models with paired bootstrap test to test significance? "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPOruEfeCJ9H"
      },
      "source": [
        "configurations_bow = [['bow'],\r\n",
        "                      ['counts', 'binary'],\r\n",
        "                      ['no_normalization', 'tf', 'tfidf'],\r\n",
        "                      ['unigram', 'bigram', 'trigram', 'all'],\r\n",
        "                      ['num_sentences', 'num_words_lt', 'num_words_gt']\r\n",
        "                      ]\r\n",
        "configurations_embeddings = [['embedding'],\r\n",
        "                             ['glove'], # fasttext\r\n",
        "                             ['num_sentences', 'num_words_lt', 'num_words_gt']\r\n",
        "                             ]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf84dU5GDRJ7"
      },
      "source": [
        "df = text_cleaning(df)\r\n",
        "doc_processed = df.iloc[0].sentences_cleaned # version for modeling\r\n",
        "doc_display = df.iloc[0].sentences # version for display (original punctuation, capitalization etc.)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbvnFi8EB3r_",
        "outputId": "3373429b-fd91-4d2d-ce32-2c401e9c044f"
      },
      "source": [
        "config_results = {}\r\n",
        "config_list = list(itertools.product(*configurations_bow)) + list(itertools.product(*configurations_embeddings))\r\n",
        "for config in config_list:\r\n",
        "  print(config)\r\n",
        "  local_results = {}\r\n",
        "\r\n",
        "  bow = vector_representation(doc_processed, config)\r\n",
        "  pr = pagerank(bow)  \r\n",
        "  local_results['predicted_summary'] = extract_summary(pr, doc_display, config) \r\n",
        "  local_results['actual_summary'] = df.iloc[0].sentences_summary\r\n",
        "  local_results['rouge'] = evaluate(local_results['predicted_summary'], local_results['actual_summary'])\r\n",
        "\r\n",
        "  config_results[str(config)] = local_results"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('bow', 'counts', 'no_normalization', 'unigram', 'num_sentences')\n",
            "('bow', 'counts', 'no_normalization', 'unigram', 'num_words_lt')\n",
            "('bow', 'counts', 'no_normalization', 'unigram', 'num_words_gt')\n",
            "('bow', 'counts', 'no_normalization', 'bigram', 'num_sentences')\n",
            "('bow', 'counts', 'no_normalization', 'bigram', 'num_words_lt')\n",
            "('bow', 'counts', 'no_normalization', 'bigram', 'num_words_gt')\n",
            "('bow', 'counts', 'no_normalization', 'trigram', 'num_sentences')\n",
            "('bow', 'counts', 'no_normalization', 'trigram', 'num_words_lt')\n",
            "('bow', 'counts', 'no_normalization', 'trigram', 'num_words_gt')\n",
            "('bow', 'counts', 'no_normalization', 'all', 'num_sentences')\n",
            "('bow', 'counts', 'no_normalization', 'all', 'num_words_lt')\n",
            "('bow', 'counts', 'no_normalization', 'all', 'num_words_gt')\n",
            "('bow', 'counts', 'tf', 'unigram', 'num_sentences')\n",
            "('bow', 'counts', 'tf', 'unigram', 'num_words_lt')\n",
            "('bow', 'counts', 'tf', 'unigram', 'num_words_gt')\n",
            "('bow', 'counts', 'tf', 'bigram', 'num_sentences')\n",
            "('bow', 'counts', 'tf', 'bigram', 'num_words_lt')\n",
            "('bow', 'counts', 'tf', 'bigram', 'num_words_gt')\n",
            "('bow', 'counts', 'tf', 'trigram', 'num_sentences')\n",
            "('bow', 'counts', 'tf', 'trigram', 'num_words_lt')\n",
            "('bow', 'counts', 'tf', 'trigram', 'num_words_gt')\n",
            "('bow', 'counts', 'tf', 'all', 'num_sentences')\n",
            "('bow', 'counts', 'tf', 'all', 'num_words_lt')\n",
            "('bow', 'counts', 'tf', 'all', 'num_words_gt')\n",
            "('bow', 'counts', 'tfidf', 'unigram', 'num_sentences')\n",
            "('bow', 'counts', 'tfidf', 'unigram', 'num_words_lt')\n",
            "('bow', 'counts', 'tfidf', 'unigram', 'num_words_gt')\n",
            "('bow', 'counts', 'tfidf', 'bigram', 'num_sentences')\n",
            "('bow', 'counts', 'tfidf', 'bigram', 'num_words_lt')\n",
            "('bow', 'counts', 'tfidf', 'bigram', 'num_words_gt')\n",
            "('bow', 'counts', 'tfidf', 'trigram', 'num_sentences')\n",
            "('bow', 'counts', 'tfidf', 'trigram', 'num_words_lt')\n",
            "('bow', 'counts', 'tfidf', 'trigram', 'num_words_gt')\n",
            "('bow', 'counts', 'tfidf', 'all', 'num_sentences')\n",
            "('bow', 'counts', 'tfidf', 'all', 'num_words_lt')\n",
            "('bow', 'counts', 'tfidf', 'all', 'num_words_gt')\n",
            "('bow', 'binary', 'no_normalization', 'unigram', 'num_sentences')\n",
            "('bow', 'binary', 'no_normalization', 'unigram', 'num_words_lt')\n",
            "('bow', 'binary', 'no_normalization', 'unigram', 'num_words_gt')\n",
            "('bow', 'binary', 'no_normalization', 'bigram', 'num_sentences')\n",
            "('bow', 'binary', 'no_normalization', 'bigram', 'num_words_lt')\n",
            "('bow', 'binary', 'no_normalization', 'bigram', 'num_words_gt')\n",
            "('bow', 'binary', 'no_normalization', 'trigram', 'num_sentences')\n",
            "('bow', 'binary', 'no_normalization', 'trigram', 'num_words_lt')\n",
            "('bow', 'binary', 'no_normalization', 'trigram', 'num_words_gt')\n",
            "('bow', 'binary', 'no_normalization', 'all', 'num_sentences')\n",
            "('bow', 'binary', 'no_normalization', 'all', 'num_words_lt')\n",
            "('bow', 'binary', 'no_normalization', 'all', 'num_words_gt')\n",
            "('bow', 'binary', 'tf', 'unigram', 'num_sentences')\n",
            "('bow', 'binary', 'tf', 'unigram', 'num_words_lt')\n",
            "('bow', 'binary', 'tf', 'unigram', 'num_words_gt')\n",
            "('bow', 'binary', 'tf', 'bigram', 'num_sentences')\n",
            "('bow', 'binary', 'tf', 'bigram', 'num_words_lt')\n",
            "('bow', 'binary', 'tf', 'bigram', 'num_words_gt')\n",
            "('bow', 'binary', 'tf', 'trigram', 'num_sentences')\n",
            "('bow', 'binary', 'tf', 'trigram', 'num_words_lt')\n",
            "('bow', 'binary', 'tf', 'trigram', 'num_words_gt')\n",
            "('bow', 'binary', 'tf', 'all', 'num_sentences')\n",
            "('bow', 'binary', 'tf', 'all', 'num_words_lt')\n",
            "('bow', 'binary', 'tf', 'all', 'num_words_gt')\n",
            "('bow', 'binary', 'tfidf', 'unigram', 'num_sentences')\n",
            "('bow', 'binary', 'tfidf', 'unigram', 'num_words_lt')\n",
            "('bow', 'binary', 'tfidf', 'unigram', 'num_words_gt')\n",
            "('bow', 'binary', 'tfidf', 'bigram', 'num_sentences')\n",
            "('bow', 'binary', 'tfidf', 'bigram', 'num_words_lt')\n",
            "('bow', 'binary', 'tfidf', 'bigram', 'num_words_gt')\n",
            "('bow', 'binary', 'tfidf', 'trigram', 'num_sentences')\n",
            "('bow', 'binary', 'tfidf', 'trigram', 'num_words_lt')\n",
            "('bow', 'binary', 'tfidf', 'trigram', 'num_words_gt')\n",
            "('bow', 'binary', 'tfidf', 'all', 'num_sentences')\n",
            "('bow', 'binary', 'tfidf', 'all', 'num_words_lt')\n",
            "('bow', 'binary', 'tfidf', 'all', 'num_words_gt')\n",
            "('embedding', 'glove', 'num_sentences')\n",
            "('embedding', 'glove', 'num_words_lt')\n",
            "('embedding', 'glove', 'num_words_gt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4rZkQzcEGoF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92941217-e556-409b-fe56-196a7082beca"
      },
      "source": [
        "max_rouge1_fmeasure = 0\r\n",
        "best_config = ''\r\n",
        "for k,v in config_results.items():\r\n",
        "  fmeasure = v['rouge']['rouge1'].fmeasure\r\n",
        "  if fmeasure > max_rouge1_fmeasure:\r\n",
        "    max_rouge1_fmeasure = fmeasure\r\n",
        "    best_config = k\r\n",
        "best_config"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"('bow', 'counts', 'no_normalization', 'unigram', 'num_words_lt')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiTHd0c2hhPr",
        "outputId": "fc4b510b-1320-4c34-d498-0c83b9b6eed0"
      },
      "source": [
        "config_results[\"('embedding', 'glove')\"]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'actual_summary': ['Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"',\n",
              "  'Obama sends a letter to the heads of the House and Senate',\n",
              "  'Obama to seek congressional approval on military action against Syria',\n",
              "  'Aim is to determine whether CW were used, not by whom, says U.N. spokesman'],\n",
              " 'predicted_summary': ['Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons.',\n",
              "  \"Bergen:  Syria is a problem from hell for the U.S.  Obama: 'This menace must be confronted'  Obama's senior advisers have debated the next steps to take, and the president's comments Saturday came amid mounting political pressure over the situation in Syria.\",\n",
              "  'Why Russia, China, Iran stand by Assad  Syria\\'s government unfazed  After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels.'],\n",
              " 'rouge': {'rouge1': Score(precision=0.5, recall=0.18571428571428572, fmeasure=0.2708333333333333),\n",
              "  'rouge2': Score(precision=0.19607843137254902, recall=0.07194244604316546, fmeasure=0.10526315789473684),\n",
              "  'rougeL': Score(precision=0.3269230769230769, recall=0.12142857142857143, fmeasure=0.17708333333333331)}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deqHkWtUGuYQ",
        "outputId": "2435b53b-d19f-45ea-f84c-bb62add995d4"
      },
      "source": [
        "config_results[\"('bow', 'binary', 'no_normalization', 'bigram')\"]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'actual_summary': ['Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"',\n",
              "  'Obama sends a letter to the heads of the House and Senate',\n",
              "  'Obama to seek congressional approval on military action against Syria',\n",
              "  'Aim is to determine whether CW were used, not by whom, says U.N. spokesman'],\n",
              " 'predicted_summary': ['Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons.',\n",
              "  'He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\"',\n",
              "  \"5 key assertions: U.S. intelligence report on Syria  Syria: Who wants what after chemical weapons horror  Reactions mixed to Obama's speech  A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama's announcement.\"],\n",
              " 'rouge': {'rouge1': Score(precision=0.5384615384615384, recall=0.25688073394495414, fmeasure=0.3478260869565218),\n",
              "  'rouge2': Score(precision=0.21568627450980393, recall=0.10185185185185185, fmeasure=0.13836477987421383),\n",
              "  'rougeL': Score(precision=0.36538461538461536, recall=0.1743119266055046, fmeasure=0.23602484472049692)}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}