{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstractive_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNT7h8mTWahLamUtsF4M6oR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katrina906/CS6120-Summarization-Project/blob/main/abstractive_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAOZbr_ZKrFG",
        "outputId": "44be91a6-2e9e-4dd7-d8e0-ecf3e440c9b5"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install import-ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8bU5xLtH6zu"
      },
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import torch\n",
        "import import_ipynb\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI-pdbylWSEy"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfBx2K5uz7_U",
        "outputId": "bd448df3-a017-4b9a-be04-6775c4c55e4e"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ra--fQLrI0",
        "outputId": "03ab243e-8343-45c6-a433-d1fb2e64f746"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bubbIbqiVTTJ",
        "outputId": "1e99e9b7-295e-4baf-e27b-88b040b021c1"
      },
      "source": [
        "# load in functions from extract_summarization notebook\n",
        "%cd \"drive/MyDrive/Colab Notebooks\"\n",
        "from attention import *\n",
        "%cd .."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "importing Jupyter notebook from attention.ipynb\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTjrh_-RLggE"
      },
      "source": [
        "# load data\n",
        "df = pd.read_pickle(\"/content/drive/MyDrive/data/cleaned_df.pkl\")\n",
        "df = df.sample(frac = 1, random_state = 123).head(1000) # so comparable to extractive 10000. or only eval on ones we use for extractive? specific test set?\n",
        "#article = df.iloc[0].text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQJSGv_MXCT7"
      },
      "source": [
        "# TODO split into train, validate, and test. supervised learning. validate for training, test for statistics"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0_qH9aKbACj"
      },
      "source": [
        "df[['sentences', 'sentences_summary']] # TODO use cleaned text\n",
        "df['text_seq'] = df.sentences.map(lambda row: ' '.join(row))\n",
        "df['summary_seq'] = df.sentences_summary.map(lambda row: '_START_ ' + ' '.join(row) + ' _END_')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzFnKA7Va-db"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "text_tr, text_test, summary_tr, summary_test = train_test_split(df['text_seq'].to_list(), df['summary_seq'].to_list(), test_size=0.1, random_state=0, shuffle=True) \n",
        "text_tr, text_val, summary_tr, summary_val = train_test_split(text_tr, summary_tr, test_size=0.1, random_state=0, shuffle=True) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tYX5bg3dap8"
      },
      "source": [
        "max_len_text = 100 # TODO set max len to actual max len "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E5WbM76XqB5"
      },
      "source": [
        "def generate_token_sequences(text, tokenizer):\n",
        "  seq = tokenizer.texts_to_sequences(list(text))\n",
        "  seq = pad_sequences(seq,  maxlen=max_len_text, padding='post') \n",
        "  voc_size = len(tokenizer.word_index) \n",
        "\n",
        "  return seq, voc_size"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1haBUAKnKal"
      },
      "source": [
        "# fit tokenizer on text training data. Same tokenizer for train and validation sets. \n",
        "# if word exists in validation but not in train, then will not be able to predict\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(list(text_tr))\n",
        "\n",
        "tokenizer_summary = Tokenizer()\n",
        "tokenizer_summary.fit_on_texts(list(summary_tr))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipuA5O7HX70y"
      },
      "source": [
        "text_tr, text_tr_voc_size = generate_token_sequences(text_tr, tokenizer)\n",
        "summary_tr, summary_tr_voc_size = generate_token_sequences(summary_tr, tokenizer_summary)\n",
        "text_val, text_val_voc_size = generate_token_sequences(text_val, tokenizer)\n",
        "summary_val, summary_val_voc_size = generate_token_sequences(summary_val, tokenizer_summary)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGSAV6UzntUF"
      },
      "source": [
        "reverse_word_index_summary=tokenizer_summary.index_word \n",
        "reverse_word_index_text=tokenizer.index_word \n",
        "word_index_summary=tokenizer_summary.word_index"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bJtqQ9dWhFZ"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 10 # 500 TODO tune?"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26NM1tDLXakK"
      },
      "source": [
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(text_tr_voc_size+1, latent_dim,trainable=True)(encoder_inputs) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLgBKFbyXbzr"
      },
      "source": [
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# TODO different numbers of layers"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHSIE2eaYvx5"
      },
      "source": [
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(summary_tr_voc_size+1, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0idt9memYiDK"
      },
      "source": [
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(summary_tr_voc_size+1, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1vCd0clYz5p",
        "outputId": "3fca5e0e-8dc5-4318-c713-40f862e04e33"
      },
      "source": [
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 10)      303950      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 100, 10), (N 840         embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 100, 10), (N 840         lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10)     81950       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 100, 10), (N 840         lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 10), ( 840         embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 10), ( 210         lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 20)     0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 8195)   172095      concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 561,565\n",
            "Trainable params: 561,565\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLupllHPY97y"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy') # TODO try diff optimizers, loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rzad3MAY-vp"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1) # TODO look at documentation"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4UepnhWZDIB",
        "outputId": "0033d646-5588-4392-d964-6c8ca6eb7ad6"
      },
      "source": [
        "history=model.fit([text_tr,summary_tr[:,:-1]],\n",
        "                  summary_tr.reshape(summary_tr.shape[0],summary_tr.shape[1], 1)[:,1:],\n",
        "                  epochs=3, # 50\n",
        "                  callbacks=[es],\n",
        "                  batch_size=512, # 512\n",
        "                  validation_data=([text_val,summary_val[:,:-1]], summary_val.reshape(summary_val.shape[0],summary_val.shape[1], 1)[:,1:]))\n",
        "# https://keras.io/api/models/model_training_apis/#fit-method\n",
        "# why is it using x and y as the x data?\n",
        "# shifting summary data in both cases?"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2/2 [==============================] - 38s 2s/step - loss: 9.0104 - val_loss: 8.9987\n",
            "Epoch 2/3\n",
            "2/2 [==============================] - 1s 365ms/step - loss: 8.9981 - val_loss: 8.9822\n",
            "Epoch 3/3\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 8.9820 - val_loss: 8.9564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "EbdFkm0KgpMU",
        "outputId": "916708f5-9d47-4a58-8666-4c2ea788524c"
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmg_NbcHkg1N"
      },
      "source": [
        "\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Y02I43kizV"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = word_index_summary['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, 1:]) # TODO added 1: to :\n",
        "        sampled_token = reverse_word_index_summary[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ1OkLWOy5ZU"
      },
      "source": [
        "max_len_summary = 100"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlIRwyz3y9ED",
        "outputId": "897dde0d-b264-4c23-dc4e-a5185cb7e8c0"
      },
      "source": [
        "text_val[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    8,   481,    21,   562,   115,   151,  2937,   322,    43,\n",
              "          21,    18,  2579,   253,     2,  2557,    39,     1,  1282,\n",
              "          66,   151,   455,   672,  3981,    31,   229,     2,  1118,\n",
              "           1,  6784,     3,    17,  8512,    26,    56,   974,    11,\n",
              "          35,   912,   500,  3421,     6,  1166,    13,   101,    16,\n",
              "          13,   927,    58,   470,     5,  2601,    19,     1,  2954,\n",
              "         789,    15,    17,  2539, 28127,     5,   724,    31,  2416,\n",
              "         304,    11,   640,   502,    14,   845,     1,  2525,     3,\n",
              "           1,  1372,     7,     9,  8270,    11,    17,  1225,    63,\n",
              "        5311,    17,  2539,     2,     5,  2920,  7469,     3,    46,\n",
              "         493,   183,   467,    61,    21,  1066,     2,   128,    49,\n",
              "         216], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "f3-ZJnVAmBoT",
        "outputId": "ba0dcb31-77a7-4d55-edcd-237eb58952aa"
      },
      "source": [
        "decode_sequence(text_val[0].reshape(1,max_len_text))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' said said said car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car car'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbjEQsSbL78Y"
      },
      "source": [
        "#summarizer = pipeline(\"summarization\", framework = 'pt')\n",
        "#summarized = summarizer(article, min_length=0, max_length=100) # max length is number of words/tokens\n",
        "# max number of tokens can consider: 1024. Need to limit to first 1024\n",
        "  # ok because best info tends to be at front of articles (and bcg documents bc pyramid principle)\n",
        "  # potential extension is to fine tune with a higher max allowed"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFdhMj2eU_xi"
      },
      "source": [
        "# https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwu082qOoXrt"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}