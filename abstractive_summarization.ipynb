{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstractive_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/gW+kCLQDV5zPFo5KwBGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katrina906/CS6120-Summarization-Project/blob/main/abstractive_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAOZbr_ZKrFG"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install import-ipynb\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8bU5xLtH6zu"
      },
      "source": [
        "from transformers import pipeline\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import pandas as pd\n",
        "import torch\n",
        "import import_ipynb\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ra--fQLrI0",
        "outputId": "cd999089-db01-4821-a6f0-2499685f4904"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCw2ywgnK-vF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bubbIbqiVTTJ",
        "outputId": "b3e1e46b-3f64-44eb-fb75-2926c8671d70"
      },
      "source": [
        "# load in functions from extract_summarization notebook\n",
        "%cd \"drive/MyDrive/Colab Notebooks\"\n",
        "from extractive_summarization import *\n",
        "%cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "importing Jupyter notebook from extractive_summarization.ipynb\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjOIZN1TKyvO"
      },
      "source": [
        "df = data_setup(n = 10000) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0_qH9aKbACj"
      },
      "source": [
        "df['text_seq'] = df.sentences.map(lambda row: ' '.join(row))\n",
        "df['text_seq_cleaned'] = df.sentences_cleaned.map(lambda row: ' '.join(row))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-uk4KYmC6E9"
      },
      "source": [
        "# initialize the model architecture and weights\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "# initialize the model tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU85RbmGFzBv",
        "outputId": "8a8c9149-1174-4d9d-9c8c-108552f9405e"
      },
      "source": [
        "inputs = tokenizer.encode(\"summarize: \" + df.text_seq.head(1).values[0], return_tensors=\"pt\", max_length=1017, truncation=True) # note this is max length, cannot go beyond"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0rkvPj_C51F"
      },
      "source": [
        "outputs = model.generate(\n",
        "    inputs, \n",
        "    max_length=150, \n",
        "    min_length=40, \n",
        "    length_penalty=2.0, \n",
        "    num_beams=4, \n",
        "    early_stopping=True) # TODO tune!\n",
        "#https://www.thepythoncode.com/article/text-summarization-using-huggingface-transformers-python\n",
        "#https://huggingface.co/blog/how-to-generate"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVxLZ7GEMcAe",
        "outputId": "c7ea3156-cb52-4523-9c8e-94fa083505af"
      },
      "source": [
        "print(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad> football clubs around the world are starting to make efforts to become more ecofriendly a 2008 survey by ethical consumer found that manchester city were the greenest among its achievements. german club nuremberg has a cistern that can hold 1000 cubic meters of water and solar panels are used to heat water for the toilets dartford fc have a scheme to provide the city of trondheim with hot water.</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Zj7Y8LLMqF",
        "outputId": "cea92e08-dde6-4f2b-f7f3-faf4dd38ce2c"
      },
      "source": [
        "print(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad> artificial pitches can save 20000 liters of water a day football stadiums have a huge carbon footprint just keeping a pitch in top condition requires regular watering underpitch heating to prevent freezing in the winter. manchester city have reduced landfill by 85 percent moved to electric vehicles at the ground and used ecofriendly paper for matchday programs. english nonleague club dartford fc has shown that small clubs arent the only ones that can afford to be ecofriendly.</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hnuYkkgC5GM",
        "outputId": "57b9dace-e3fa-4900-cf24-612d9491ed3d"
      },
      "source": [
        "print(tokenizer.decode(outputs[0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad> football clubs around the world are starting to make efforts to become more eco-friendly. a survey by \"ethical consumer\" found that manchester city was the greenest. dartford's princes park stadium has a \"living roof\" of plants that provide a natural air filtration system.</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59MyTKnEKMa9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RK3iGxSKL_l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iiJqXN4KL5e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbjEQsSbL78Y"
      },
      "source": [
        "#summarizer = pipeline(\"summarization\", framework = 'pt')\n",
        "#summarized = summarizer(article, min_length=0, max_length=100) # max length is number of words/tokens\n",
        "# max number of tokens can consider: 1024. Need to limit to first 1024\n",
        "  # ok because best info tends to be at front of articles (and bcg documents bc pyramid principle)\n",
        "  # potential extension is to fine tune with a higher max allowed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFdhMj2eU_xi"
      },
      "source": [
        "# https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}